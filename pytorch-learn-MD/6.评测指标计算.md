## 六、评测指标计算

### 1. 准确率

#### Ⅰ torch.max()

```python
torch.max(input, dim)
```

在分类问题中，通常需要使用`max()`函数对`softmax`函数的输出值进行操作

    输入
        input是softmax函数输出的一个tensor
        dim是max函数索引的维度0/1，0是每列的最大值，1是每行的最大值
        
     输出
        函数会返回两个tensor，第一个tensor是每行的最大值，softmax的输出中最大的是1，所以第一个tensor是全1的tensor；第二个tensor是每行最大值的索引。

样例如下

```python
import torch
a = torch.tensor([[1,5,62,54], [2,6,2,6], [2,65,2,6]])
print(a)

# 输出如下：
tensor([[ 1,  5, 62, 54],
        [ 2,  6,  2,  6],
        [ 2, 65,  2,  6]])

```

返回每行的最大值及其下标

```python
out = torch.max(a, 1)
print(out)

# 输出如下：
torch.return_types.max(
values=tensor([62,  6, 65]),
indices=tensor([2, 1, 1]))
```

分别接受返回值

```python
data, lables = torch.max(input=a,dim=1)
print(data)
print(lables)

# 输出如下：
tensor([62,  6, 65])
tensor([2, 1, 1])
```

计算准确率

```python
import torch

lables = torch.tensor([3, 1, 1])  # 真实标签
total_num = lables.shape[0]  # 总的样本数量为3
# data = model(data)
data = torch.tensor([[1, 2, 3, 4], [3, 12, 2, 3], [3, 4, 67, 8]])  # 经过模型处理的输出值
pred_lables = torch.max(input=data, dim=1)[1]  # [3, 1, 2]
acc = (pred_lables == lables).sum().item() / total_num
print(acc)

# 输出如下
0.6666666666666666
```

#### Ⅱ torch.argmax()

```python
torch.argmax(input, dim=None, keepdim=False)
```

和上面的max很想，只有一个返回值，只返回对应维度最大值的下标

```python
import torch
a=torch.tensor([
              [
                  [1, 5, 5, 2],
                  [9, -6, 2, 8],
                  [-3, 7, -9, 1]
              ],
 
              [
                  [-1, 7, -5, 2],
                  [9, 6, 2, 8],
                  [3, 7, 9, 1]
              ]])
b=torch.argmax(a,dim=0)
print(b)
print(a.shape)
 
"""
tensor([[0, 1, 0, 1],
        [1, 1, 1, 1],
        [1, 1, 1, 1]])
torch.Size([2, 3, 4])"""
 
#dim=0,即将第一个维度消除，也就是将两个[3*4]矩阵只保留一个，因此要在两组中作比较，即将上下两个[3*4]的矩阵分别在对应的位置上比较
 
b=torch.argmax(a,dim=1)
“”“
tensor([[1, 2, 0, 1],
        [1, 2, 2, 1]])
torch.Size([2, 3, 4])”“”
#dim=1，即将第二个维度消除,这么理解：矩阵维度变为[2*4];
"""[1, 5, 5, 2],
   [9, -6, 2, 8],
   [-3, 7, -9, 1];
纵向压缩成一维，因此变为[1,2,0,1];同理得到[1,2,2,1];"""
b=torch.argmax(a,dim=2)
"""
tensor([[2, 0, 1],
        [1, 0, 2]])
"""
#dim=2,即将第三个维度消除，这么理解：矩阵维度变为[2*3]
"""
   [1, 5, 5, 2],
   [9, -6, 2, 8],
   [-3, 7, -9, 1];
横向压缩成一维
[2,0,1],同理得到下面的“”“
```

